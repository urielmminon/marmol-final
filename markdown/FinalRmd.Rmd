---
title: "Proyecto Final Minería y Análisis de Datos"
author: "Héctor Corro 114350, Uriel Miranda 177508, Itzel Muñoz 122803"
date: "Diciembre 2018"
#output: html_document
output: 
  html_document:
    toc: 2
    toc_float: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = F, error = F, message = F)
library(readr)
library(tidyverse)
library(dplyr)
library(data.table)
library(ggplot2)
library(feather)
library(stringr)
library(plotly)
library(ggridges)
library(ggpubr)
#library(tidyverse)
```

##Antecedentes

Walmart es la cadena de retail más grande en el mundo; fue fundada por Sam Walton 1962 y desde entonces ha tenido un gran crecimiento llegando a cotizar en la bolsa de Nueva York en 1972. Actualmente Walmart ha entendido el valor de la información y con sus 20,000 tiendas en 28 países entiende que los datos que generan están muy poco aprovechados. Con esto en mente Walmart ha creado una nube privada que enfrenta alrededor de 2.5 Petabytes de información cada hora y ha creado también “The Data Café” que es un hub punta de lanza en analítica con la finalidad de aprovechar de mejor manera esa cantidad de información.
La necesidad de encontrar insights que puedan accionar cambios es lo que está moviendo a la empresa y sus esfuerzos en el mediano y largo plazo.

###Objetivo

En el presente proyecto, se realizó un modelo para categorizar las visitas que realizan los clientes a Walmart basándose únicamente en los productos que compran los clientes en su visita. La base se obtuvo de *kaggle* de la competencia titulada *"Walmart Recruiting: Trip Type Classification"*. 

Las categorías están representadas por números enteros no contiguos, y no se conoce el significado de ninguna categoría. 

La función que se busca optimizar, más específicamente minimizar, es la *pérdida logarítmica multiclase* también conocida como **log loss multiclase**, misma que se define como:

$-\frac{1}{N}\sum_{i=1}^{N}\sum_{j=1}^{M}y_{ij}log(p_{ij})$

donde $N$ es el total de visitas en el conjunto de prueba, $M$ es el total de categorías existentes (como más adelante se verá $M = 38$), $y_{ij}$ es 1 si la observación $i$ pertenece a la categoría $j$ y 0 en otro caso, $p_{ij}$ es la probabilidad obtenida por el modelo que la observación  $i$ pertenezca a la categoría $j$.

###Criterio de Éxito

Obtener un valor de la función *log loss* menor a 1 sobre el conjunto de prueba.

##Lectura y limpieza de datos

Se realiza la lectura y limpieza de datos con las funciones *utils*, *load*, *prepare* y *clean*:

```{r, echo=T}
source("utils.R")
source("00-load.R")
source("01-prepare.R")
source("02-clean.R")

```

La base de datos original muestra un registro por cada producto que se compró en las diferentes visitas de los clientes en la tienda. Por ejemplo, si un cliente en su visita compró 10 productos diferentes, esa visita tiene 10 registros con el mismo identificador de visita y mismo tipo de visita. Los primeros renglones de la base son los siguientes:

```{r, echo=F}
head(data.frame(walmart))
```

Las variables con las que se cuenta en la base de datos son:

* TripType - es una variable categórica que indica el tipo de visita que realizó una persona en Walmart, es la variable objetivo que se busca predecir
* VisitNumber - es el identificador único para cada visita que realizaron los diferentes clientes a Walmart
* Weekday - día de la semana en que el cliente realizó la visita a Walmart
* Upc - es un código para identificar de forma única los productos de Walmart
* ScanCount - número de productos de un tipo específico que se compararon, si el valor es -1 indica una devolución de producto
* DepartmentDescription - departamente al cual pertenece el producto
* FinelineNumber - código para identificar los productos de una forma más general que el código Upc pero más granular que el departamento


La estructura original de la base no tiene registros únicos a nivel visita, esto complica el ajuste del modelo pues las categorías son a nivel visita. Si se trabajara con la base original, se estaría ajustando una categoría a nivel producto en lugar de a nivel visita. Por lo tanto, el tratamiento que se realizó a los datos consistió en construir la base de forma que tenga un solo renglón por visita. La variable de día de la semana es a nivel visita, por lo que no sufrió modificaciones. Respecto a las variables del departamento y número de productos, se crearon tantas columnas como departamentos existen, 68 en total, y se sumaron de acuerdo al número de productos por departamento comprados por visita. La base creada y utilizada para modelar luce como sigue:

```{r}
head(walmartSpread, n=10)
```

En cuanto a la limpieza, ésta consistió en unificar dos departamentos *MENS WEAR* con *MENSWEAR*; para todas las variables de departamento se cambiaron los NA's por 0, pues en realidad los valores nulos de esas variables son porque se realizaron cero compras de ese departamento en la respectiva visita. En los nombres de las variables, se sustituyeron los espacios por guiones bajos y se eliminaron caracteres especiales (las comas y los &) para facilitar el manejo de la base en el análisis exploratorio.

De esta manera, se obtiene una base de datos con 95'674 registros (únicos a nivel visita) y 69 variables explicativas.

##Análisis Exploratorio

En primer lugar, se analiza la variable objetivo: el tipo de visita realizada en Walmart. Su distribución luce como se muestra en la siguiente gráfica:

```{r, echo=F}

p <- ggplot(walmartSpread) +
  geom_bar(mapping=aes(as.factor(TripType)), fill = "#56B4E9") + 
  xlab("Tipo de Compra") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
ggplotly(p)

```

Se observa que existen categorías que sobresalen respecto a las demás, estas categorías son: 8, 9, 39, 40 y 999. Por el contrario, existen categorías que tienen muy poca presencia en los datos, por ejemplo la 12, 14 y 23, estas categorías con poca representación en los datos muy probablemente serán complicadas de modelar. Para tener mayor detalle se obtienen las frecuencias por categoría:


```{r, echo=F}
summary(as.factor(walmartSpread$TripType))
```

###Análisis Univariado

Se realiza ahora el análisis univariado sobre las variables explicativas.

El día de la semana tiene la siguiente distribución:


```{r, echo = F}
aux <- walmartSpread
aux$Weekday <- factor(aux$Weekday, levels = c("Monday","Tuesday","Wednesday","Thursday",
                                              "Friday","Saturday","Sunday"))
ggplot(aux) +
  geom_bar(mapping=aes(Weekday), fill = "#56B4E9") + 
  xlab("Día de la semana") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

```

Notoriamente, la mayoría de las visitas se realizan entre el viernes y el domingo, principalmente el fin de semana. Resulta curioso que el día de la semana con menos visitas es el jueves.


Las visitas realizadas cada día de la semana son las siguientes:

```{r, echo=F}
summary(as.factor(aux$Weekday))
rm(aux)
```

El departmento al cual pertenecen los productos comprados y devueltos tiene la siguiente distribución:

```{r}
deptos <- walmart %>% group_by(DepartmentDescription) %>% 
  summarise(.,total=sum(ScanCount))

p <- ggplot(deptos, aes(x=DepartmentDescription, y=total)) +
  geom_bar(fill = "#56B4E9", stat="identity") + 
  xlab("Departamento") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
ggplotly(p)
```

Como era de esperarse, existen departamentos con mucha población y departamentos con escasa población.

Es importante recordar que la estructura de la base transformada tiene una columna por cada departamento, por lo tanto la distribución real de cada variable de departamento tiene distribuciones muy concentradas en el cero, por ejemplo:

```{r, echo=F}
#lista <- names(walmartSpread[,4:71])
#i <- 1
a1 <- ggplot(walmartSpread) +
      geom_histogram(mapping=aes_string("HR_PHOTO"), fill = "#56B4E9")
a2 <- ggplot(walmartSpread) +
      geom_histogram(mapping=aes_string("COMM_BREAD"), fill = "#56B4E9")
a3 <- ggplot(walmartSpread) +
      geom_histogram(mapping=aes_string("PERSONAL_CARE"), fill = "#56B4E9")
a4 <- ggplot(walmartSpread) +
      geom_histogram(mapping=aes_string("SERVICE_DELI"), fill = "#56B4E9")

    gridExtra::grid.arrange(a1, a2, a3, a4, ncol=2)
```

Incluso en el departamento más pobaldo *GROCERY DRY GOODS*, la distribución está bastante concentrada en el cero:

```{r}
ggplot(walmartSpread) +
        geom_histogram(mapping=aes(GROCERY_DRY_GOODS), fill = "#56B4E9")
```


###Análisis Bivariado

Resulta complicado visualizar las gráficas de la variable objetivo con las variables explicativas, pues el tipo de visita puede tomar 38 valores diferentes. Por ello, se realizarán gráficas separadas, mostrando de 10 en 10 las categorías.

La distribución del día de la semana en que se realiza la visita, para cada categoría se muestra a continuación:

```{r}
aux <- walmartSpread[walmartSpread$TripType <= 15,]
aux$Weekday <- factor(aux$Weekday, levels = c("Monday","Tuesday","Wednesday","Thursday",
                                              "Friday","Saturday","Sunday"))

p <- ggplot(aux) + 
  geom_bar(mapping = aes(Weekday, fill = Weekday)) + 
  facet_grid(as.factor(aux$TripType) ) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, size=6) ) +
  theme(legend.position = "none") + xlab("") + ylim(c(0,2000))
ggplotly(p)


aux <- walmartSpread[walmartSpread$TripType > 15 
                     & as.numeric(walmartSpread$TripType) <= 27,] 
aux$Weekday <- factor(aux$Weekday, levels = c("Monday","Tuesday","Wednesday","Thursday",
                                              "Friday","Saturday","Sunday"))

p <- ggplot(aux) + 
  geom_bar(mapping = aes(Weekday, fill = Weekday)) + 
  facet_grid(as.factor(aux$TripType) ) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, size=6) ) +
  theme(legend.position = "none") + xlab("") + ylim(c(0,2000))
ggplotly(p)

aux <- walmartSpread[walmartSpread$TripType > 27 
                     & walmartSpread$TripType <= 37,]
aux$Weekday <- factor(aux$Weekday, levels = c("Monday","Tuesday","Wednesday","Thursday",
                                              "Friday","Saturday","Sunday"))

p <- ggplot(aux) + 
  geom_bar(mapping = aes(Weekday, fill = Weekday)) + 
  facet_grid(as.factor(aux$TripType) ) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, size=6) ) +
  theme(legend.position = "none") + xlab("") + ylim(c(0,2000))
ggplotly(p)

aux <- walmartSpread[walmartSpread$TripType > 37,]
aux$Weekday <- factor(aux$Weekday, levels = c("Monday","Tuesday","Wednesday","Thursday",
                                              "Friday","Saturday","Sunday"))

p <- ggplot(aux) + 
  geom_bar(mapping = aes(Weekday, fill = Weekday)) + 
  facet_grid(as.factor(aux$TripType) ) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, size=6) ) +
  theme(legend.position = "none") + xlab("") + ylim(c(0,2000))
ggplotly(p)

```

Teniendo en mente la gráfica univariada del día de la semana que se mostró en la sección anterior, y contrastando con la distribución de esta variable para cada categoría, se pueden detectar patrones de cada uno de los tipos de visita. Mencionaremos algunos de ellos:

En la categoría 3, la distribución del día de la semana es bastante diferente a la global, pues tienen un nivel bajo el lunes, comienza a subir, disimuye el jueves y llega a su máximo en viernes, descendiendo el fin de semana.

En la categoría 25, las visitas a Walmart tienen su menor número en lunes, y van a aumentando día a día llegando a su máximo el domingo.

Para la categoría 40, el patrón es igual al global, pero las diferencias del nivel en los diferentes días es más acentuada que en la distribución global.

Es importante mencionar, que todos los tipos de vísita alcanzan su máximo entre el viernes y el domingo.

Respecto a la variable objetivo y los distintos departamentos, nuevamente se separa en 4 gráficas y se acotó el rango del eje x de -1 a 10 para facilitar su entendimiento e interpretación.

La gráfica bivariada de la variable objetivo y el departamento con mayores compras *GROCERY DRY GOODS* se muestra a continuación:

```{r}

aux <- walmartSpread[walmartSpread$TripType <= 15,]
a1 <- ggplot(aux, aes(x = GROCERY_DRY_GOODS, y = as.factor(TripType), fill = as.factor(TripType)) ) +
  geom_density_ridges() +
  theme_ridges() + 
  theme(legend.position = "none") + ylab("TripType") +
  xlim(c(-1,10))


aux <- walmartSpread[walmartSpread$TripType > 15 
                     & as.numeric(walmartSpread$TripType) <= 27,] 
a2 <- ggplot(aux, aes(x = GROCERY_DRY_GOODS, y = as.factor(TripType), fill = as.factor(TripType)) ) +
  geom_density_ridges() +
  theme_ridges() + 
  theme(legend.position = "none") + ylab("TripType") +
  xlim(c(-1,10))

aux <- walmartSpread[walmartSpread$TripType > 27 
                     & walmartSpread$TripType <= 37,]
a3 <- ggplot(aux, aes(x = GROCERY_DRY_GOODS, y = as.factor(TripType), fill = as.factor(TripType)) ) +
  geom_density_ridges() +
  theme_ridges() + 
  theme(legend.position = "none") + ylab("TripType") +
  xlim(c(-1,10))

aux <- walmartSpread[walmartSpread$TripType > 37,] 
a4 <- ggplot(aux, aes(x = GROCERY_DRY_GOODS, y = as.factor(TripType), fill = as.factor(TripType)) ) +
  geom_density_ridges() +
  theme_ridges() + 
  theme(legend.position = "none") + ylab("TripType") +
  xlim(c(-1,10))

    gridExtra::grid.arrange(a1, a2, a3, a4, ncol=2)
```

Se observa que en la mayoría de las categorías, el departamento *GROCERY DRY GOODS* está concenctrado en el cero, pero existen categorías con distribuciones que muestran concentraciones en valores positivos. Por ejemplo 12, 15, 44 y más notoriamente en las categorías 37, 38, 39 y 40. Se puede pensar que estas categorías pueden referirse a visitas a Walmart orientadas a compras de este tipo de productos.


Ahora se analiza la distribución del departamento *DSD GROCERY* para cada tipo de categoría:

```{r}

aux <- walmartSpread[walmartSpread$TripType <= 15,]
a1 <- ggplot(aux, aes(x = DSD_GROCERY, y = as.factor(TripType), fill = as.factor(TripType)) ) +
  geom_density_ridges() +
  theme_ridges() + 
  theme(legend.position = "none") + ylab("TripType") +
  xlim(c(-1,10))


aux <- walmartSpread[walmartSpread$TripType > 15 
                     & as.numeric(walmartSpread$TripType) <= 27,] 
a2 <- ggplot(aux, aes(x = DSD_GROCERY, y = as.factor(TripType), fill = as.factor(TripType)) ) +
  geom_density_ridges() +
  theme_ridges() + 
  theme(legend.position = "none") + ylab("TripType") +
  xlim(c(-1,10))

aux <- walmartSpread[walmartSpread$TripType > 27 
                     & walmartSpread$TripType <= 37,]
a3 <- ggplot(aux, aes(x = DSD_GROCERY, y = as.factor(TripType), fill = as.factor(TripType)) ) +
  geom_density_ridges() +
  theme_ridges() + 
  theme(legend.position = "none") + ylab("TripType") +
  xlim(c(-1,10))

aux <- walmartSpread[walmartSpread$TripType > 37,] 
a4 <- ggplot(aux, aes(x = DSD_GROCERY, y = as.factor(TripType), fill = as.factor(TripType)) ) +
  geom_density_ridges() +
  theme_ridges() + 
  theme(legend.position = "none") + ylab("TripType") +
  xlim(c(-1,10))

    gridExtra::grid.arrange(a1, a2, a3, a4, ncol=2)
```

Este departamento resulta ser más interesante, pues tiene muchas menos categorías concentradas en el cero. Por ejemplo, la categoría 35 parece tener muy poca población en el cero a diferencia del departamento que se mostró anteriormente.

Ahora se realiza el análisis sobre un departamento menos poblado que los anteriores, éste es *PHARMACY OTC*:

```{r}
aux <- walmartSpread[walmartSpread$TripType <= 15,]
a1 <- ggplot(aux, aes(x = PHARMACY_OTC, y = as.factor(TripType), fill = as.factor(TripType)) ) +
  geom_density_ridges() +
  theme_ridges() + 
  theme(legend.position = "none") + ylab("TripType") +
  xlim(c(-1,10))

aux <- walmartSpread[walmartSpread$TripType > 15 
                     & as.numeric(walmartSpread$TripType) <= 27,] 
a2 <- ggplot(aux, aes(x = PHARMACY_OTC, y = as.factor(TripType), fill = as.factor(TripType)) ) +
  geom_density_ridges() +
  theme_ridges() + 
  theme(legend.position = "none") + ylab("TripType") +
  xlim(c(-1,10))

aux <- walmartSpread[walmartSpread$TripType > 27 
                     & walmartSpread$TripType <= 37,]
a3 <- ggplot(aux, aes(x = PHARMACY_OTC, y = as.factor(TripType), fill = as.factor(TripType)) ) +
  geom_density_ridges() +
  theme_ridges() + 
  theme(legend.position = "none") + ylab("TripType") +
  xlim(c(-1,10))

aux <- walmartSpread[walmartSpread$TripType > 37,] 
a4 <- ggplot(aux, aes(x = PHARMACY_OTC, y = as.factor(TripType), fill = as.factor(TripType)) ) +
  geom_density_ridges() +
  theme_ridges() + 
  theme(legend.position = "none") + ylab("TripType") +
  xlim(c(-1,10))

    gridExtra::grid.arrange(a1, a2, a3, a4, ncol=2)
```

En este departamento, llaman mucho la atención las categorías 4 y 5 pues son las que tienen una distribución más alejada del cero. Esto lleva a pensar que estas categorías están ligadas con la compra de productos farmacéuticos.


El análisis se vuelve más complicado cuando los departamentos están poco poblados, por ejemplo en *JEWELRY AND SUNGLASSES*, las gráficas son las siguientes:

```{r}
aux <- walmartSpread[walmartSpread$TripType <= 15,]
a1 <- ggplot(aux, aes(x = JEWELRY_AND_SUNGLASSES, y = as.factor(TripType), fill = as.factor(TripType)) ) +
  geom_density_ridges() +
  theme_ridges() + 
  theme(legend.position = "none") + ylab("TripType") +
  xlim(c(-1,5))

aux <- walmartSpread[walmartSpread$TripType > 15 
                     & as.numeric(walmartSpread$TripType) <= 27,] 
a2 <- ggplot(aux, aes(x = JEWELRY_AND_SUNGLASSES, y = as.factor(TripType), fill = as.factor(TripType)) ) +
  geom_density_ridges() +
  theme_ridges() + 
  theme(legend.position = "none") + ylab("TripType") +
  xlim(c(-1,5))

aux <- walmartSpread[walmartSpread$TripType > 27 
                     & walmartSpread$TripType <= 37,]
a3 <- ggplot(aux, aes(x = JEWELRY_AND_SUNGLASSES, y = as.factor(TripType), fill = as.factor(TripType)) ) +
  geom_density_ridges() +
  theme_ridges() + 
  theme(legend.position = "none") + ylab("TripType") +
  xlim(c(-1,5))

aux <- walmartSpread[walmartSpread$TripType > 37,] 
a4 <- ggplot(aux, aes(x = JEWELRY_AND_SUNGLASSES, y = as.factor(TripType), fill = as.factor(TripType)) ) +
  geom_density_ridges() +
  theme_ridges() + 
  theme(legend.position = "none") + ylab("TripType") +
  xlim(c(-1,5))

    gridExtra::grid.arrange(a1, a2, a3, a4, ncol=2)
```


En este departamento se redujo más el rango del eje x, de -1 a 5 para tener mejor visualización. La distribución de *joyería y lentes de sol* tiene una altísima concentración en el cero para prácticamente todas las categorías.

###Análisis Multivariado

Dada la cantidad de variables con las que se cuenta y los 38 valores que toma del tipo de visita, el análisis multivariado tiene muchas posibles combinaciones. A continuación se muestran algunas de ellas.

Se puede obtener por ejemplo, la distribución conjunta de 2 departamentos con la variable objetivo (para facilitar la visualización, se separan por grupos de categorías):

```{r}

aux <- walmartSpread[walmartSpread$TripType <= 8,]

aux$TripTypeF <- as.factor(aux$TripType)

ggscatterhist(aux, x = "DSD_GROCERY", y = "PRODUCE",
              color = "TripTypeF", alpha = 0.6,
              margin.plot = "boxplot",
              ggtheme = theme_bw() )


aux <- walmartSpread[walmartSpread$TripType > 8 & walmartSpread$TripType <= 19,]

aux$TripTypeF <- as.factor(aux$TripType)


ggscatterhist(aux, x = "DSD_GROCERY", y = "PRODUCE",
              color = "TripTypeF", alpha = 0.6,
              margin.plot = "boxplot",
              ggtheme = theme_bw() )


aux <- walmartSpread[walmartSpread$TripType > 19 & walmartSpread$TripType <= 25,]

aux$TripTypeF <- as.factor(aux$TripType)

ggscatterhist(aux, x = "DSD_GROCERY", y = "PRODUCE",
              color = "TripTypeF", alpha = 0.6,
              margin.plot = "boxplot",
              ggtheme = theme_bw() )



aux <- walmartSpread[walmartSpread$TripType > 25 & walmartSpread$TripType <= 31,]

aux$TripTypeF <- as.factor(aux$TripType)

ggscatterhist(aux, x = "DSD_GROCERY", y = "PRODUCE",
              color = "TripTypeF", alpha = 0.6,
              margin.plot = "boxplot",
              ggtheme = theme_bw() )



aux <- walmartSpread[walmartSpread$TripType > 31 & walmartSpread$TripType <= 37,]

aux$TripTypeF <- as.factor(aux$TripType)

ggscatterhist(aux, x = "DSD_GROCERY", y = "PRODUCE",
              color = "TripTypeF", alpha = 0.6,
              margin.plot = "boxplot",
              ggtheme = theme_bw() )


aux <- walmartSpread[walmartSpread$TripType > 37 & walmartSpread$TripType <= 41,]

aux$TripTypeF <- as.factor(aux$TripType)

ggscatterhist(aux, x = "DSD_GROCERY", y = "PRODUCE",
              color = "TripTypeF", alpha = 0.6,
              margin.plot = "boxplot",
              ggtheme = theme_bw() )


aux <- walmartSpread[walmartSpread$TripType > 41,]

aux$TripTypeF <- as.factor(aux$TripType)

ggscatterhist(aux, x = "DSD_GROCERY", y = "PRODUCE",
              color = "TripTypeF", alpha = 0.6,
              margin.plot = "boxplot",
              ggtheme = theme_bw() )

```

Resulta difícil interpretar las gráficas para las categorías poco pobladas. Cuando las categorías están más pobladas, por ejemplo en la 37, se observa que estos dos departamentso *PRODUCE* y *DSD GROCERY*, están dispersos el primero en valores menores a 20 y el segundo en valores menores a 10. Por el contrario en la categoría 40, los valores de *PRODUCE* son menores a 15 y los valores de *DSD GROCERY* son menores a 25.

##Feature Engineering

En cuanto a la ingeniería de características, la construcción de la base a nivel visita fue el paso esencial, pues permite encontrar un modelo más acertivo, y mas que limpieza de datos fue feature engineering . La construcción de las variables de productos comprados y/o devueltos por departamento también formaron parte del feature engineering.

Adicionalmente, se construyeron las siguientes variables a partir de las disponibles originalmente:

* Total de productos comprados en la visita

* Indicadora de devolución de productos, vale 1 si se devolvió al menos un producto en la visita y 0 en otro caso

* Total de productos devueltos en la visita

* Total de departamentos visitados, si se compró al menos un producto en el departamento éste cuenta como 1 en la suma de departamentos visitados

* Productos diferentes comprados respecto a UPC, es decir cuántos productos con diferente código UPC se compraron en la visita

* Día del mes en que se realizó la visita, se explica más adelante esta variable

```{r}

#regresar a nombres originales
colnames(walmartSpread) <- names_orig
                             
#total productos comprados
walmartSpread$total_prod <- rowSums(walmartSpread[,-c(1,2,3)])

#indicadora devoluciones

walmart.Dev <- walmart %>% group_by(VisitNumber) %>% 
  summarise(min_p = min(ScanCount)) 

walmart.Dev <- mutate(walmart.Dev, ind_dev = ifelse(min_p < 0, 1, 0))
walmart.Dev$min_p <- NULL

walmartSpread <- merge(walmartSpread,walmart.Dev, by = "VisitNumber")

# total de departamentos visitados
walmartSpread$departamentos_visitados <- apply(walmartSpread[,4:71], 1, function(x) sum(x!=0))

# cuenta de articulos diferentes basados en upc
prod_distintos <- walmart %>% filter(ScanCount>0) %>% group_by(VisitNumber) %>% summarize(prod_distintos_upc=n())
walmartSpread <- left_join(walmartSpread,prod_distintos,by=c("VisitNumber"="VisitNumber"))

# cuenta de articulos devueltos
prod_devueltos<- walmart %>% filter(ScanCount<0) %>%  arrange(VisitNumber) %>%  group_by(VisitNumber) %>% summarize(prod_devueltos=n())
walmartSpread <- left_join(walmartSpread,prod_devueltos,by=c("VisitNumber"="VisitNumber"))

walmartSpread[is.na(walmartSpread)] <- 0

```

```{r}
walmart.test <- read_csv("Datos/test.csv") 

walmart.testSpread <- walmart.test %>% group_by(VisitNumber,Weekday,DepartmentDescription) %>% 
  summarise(Count = sum(ScanCount)) %>% 
  spread(key=DepartmentDescription,value=Count)

walmart.testSpread[is.na(walmart.testSpread)] <- 0
walmart.testSpread$MENSWEAR <- walmart.testSpread$`MENS WEAR`+walmart.testSpread$MENSWEAR
walmart.testSpread <- walmart.testSpread %>% subset(select = -c(`MENS WEAR`) )
walmart.testSpread$HEALTH_AND_BEAUTY_AIDS <- 0

#total productos comprados
walmart.testSpread$total_prod <- rowSums(walmart.testSpread[,-c(1,2)])

#indicadora devoluciones

walmart.testDev <- walmart.test %>% group_by(VisitNumber) %>% 
  summarise(min_p = min(ScanCount)) 

walmart.testDev <- mutate(walmart.testDev, ind_dev = ifelse(min_p < 0, 1, 0))
walmart.testDev$min_p <- NULL

#pegar variable a la base completa
walmart.testSpread <- merge(walmart.testSpread,walmart.testDev, by = "VisitNumber")

# total de departamentos visitados
walmart.testSpread$departamentos_visitados <- apply(walmart.testSpread[,4:71], 1, function(x) sum(x!=0))


# cuenta de articulos diferentes basados en upc
prod_distintos <- walmart.test %>% filter(ScanCount>0) %>% group_by(VisitNumber) %>% summarize(prod_distintos_upc=n())
walmart.testSpread <- left_join(walmart.testSpread,prod_distintos,by=c("VisitNumber"="VisitNumber"))


# cuenta de articulos devueltos
prod_devueltos<- walmart.test %>% filter(ScanCount<0) %>%  arrange(VisitNumber) %>%  group_by(VisitNumber) %>% summarize(prod_devueltos=n())
walmart.testSpread <- left_join(walmart.testSpread,prod_devueltos,by=c("VisitNumber"="VisitNumber"))

walmart.testSpread[is.na(walmart.testSpread)] <- 0


```


```{r}
walmart.todo <- rbind(walmartSpread[,c(1,3)],walmart.testSpread[,c(1,2)])

walmart.ord <- walmart.todo[order(walmart.todo$VisitNumber),c(1,2)]


#detectar cambios de semana
viernes <- data.frame(walmart.ord[walmart.ord$Weekday=="Friday",])
viernes <- mutate(viernes, lag_v = dplyr::lag(VisitNumber, default=0))

viernes$dif <- viernes$VisitNumber - viernes$lag_v

cambio.viernes <- viernes[viernes$dif > 1 & viernes$lag_v != 0,]

##sábado

sabado <- data.frame(walmart.ord[walmart.ord$Weekday=="Saturday",])
sabado <- mutate(sabado, lag_v = dplyr::lag(VisitNumber, default=0))

sabado$dif <- sabado$VisitNumber - sabado$lag_v

cambio.sabado <- sabado[sabado$dif > 1 & sabado$lag_v != 0,]

##domingo

domingo <- data.frame(walmart.ord[walmart.ord$Weekday=="Sunday",])
domingo <- mutate(domingo, lag_v = dplyr::lag(VisitNumber, default=0))


domingo$dif <- domingo$VisitNumber - domingo$lag_v

cambio.domingo <- domingo[domingo$dif > 1 & domingo$lag_v != 0,]

##lunes

lunes <- data.frame(walmart.ord[walmart.ord$Weekday=="Monday",])
lunes <- mutate(lunes, lag_v = dplyr::lag(VisitNumber, default=0))

lunes$dif <- lunes$VisitNumber - lunes$lag_v

cambio.lunes <- lunes[lunes$dif > 1 & lunes$lag_v != 0,]

##martes

martes <- data.frame(walmart.ord[walmart.ord$Weekday=="Tuesday",])
martes <- mutate(martes, lag_v = dplyr::lag(VisitNumber, default=0))

martes$dif <- martes$VisitNumber - martes$lag_v

cambio.martes <- martes[martes$dif > 1 & martes$lag_v != 0,]

##miércoles

miercoles <- data.frame(walmart.ord[walmart.ord$Weekday=="Wednesday",])
miercoles <- mutate(miercoles, lag_v = dplyr::lag(VisitNumber, default=0))

miercoles$dif <- miercoles$VisitNumber - miercoles$lag_v

cambio.miercoles <- miercoles[miercoles$dif > 1 & miercoles$lag_v != 0,]

##jueves

jueves <- data.frame(walmart.ord[walmart.ord$Weekday=="Thursday",])
jueves <- mutate(jueves, lag_v = dplyr::lag(VisitNumber, default=0))

jueves$dif <- jueves$VisitNumber - jueves$lag_v

cambio.jueves <- jueves[jueves$dif > 1 & jueves$lag_v != 0,]

#######

jueves$cambio1 <- cambio.jueves[1,"VisitNumber"]
jueves$cambio2 <- cambio.jueves[2,"VisitNumber"]
jueves$cambio3 <- cambio.jueves[3,"VisitNumber"]

jueves <- mutate(jueves, dia_mes = ifelse(VisitNumber < cambio1, 7, 
                                              ifelse(VisitNumber < cambio2, 14, 
                                              ifelse(VisitNumber < cambio3, 21, 28)
                                                     ) 
                                              ))
##


miercoles$cambio1 <- cambio.miercoles[1,"VisitNumber"]
miercoles$cambio2 <- cambio.miercoles[2,"VisitNumber"]
miercoles$cambio3 <- cambio.miercoles[3,"VisitNumber"]

miercoles <- mutate(miercoles, dia_mes = ifelse(VisitNumber < cambio1, 6, 
                                              ifelse(VisitNumber < cambio2, 13, 
                                                     ifelse(VisitNumber < cambio3, 20, 27)
                                              ) 
))

##

martes$cambio1 <- cambio.martes[1,"VisitNumber"]
martes$cambio2 <- cambio.martes[2,"VisitNumber"]
martes$cambio3 <- cambio.martes[3,"VisitNumber"]

martes <- mutate(martes, dia_mes = ifelse(VisitNumber < cambio1, 5, 
                                                ifelse(VisitNumber < cambio2, 12, 
                                                       ifelse(VisitNumber < cambio3, 19, 26)
                                                ) 
))

##

lunes$cambio1 <- cambio.lunes[1,"VisitNumber"]
lunes$cambio2 <- cambio.lunes[2,"VisitNumber"]
lunes$cambio3 <- cambio.lunes[3,"VisitNumber"]

lunes <- mutate(lunes, dia_mes = ifelse(VisitNumber < cambio1, 4, 
                                          ifelse(VisitNumber < cambio2, 11, 
                                                 ifelse(VisitNumber < cambio3, 18, 25)
                                          ) 
))

##

domingo$cambio1 <- cambio.domingo[1,"VisitNumber"]
domingo$cambio2 <- cambio.domingo[2,"VisitNumber"]
domingo$cambio3 <- cambio.domingo[3,"VisitNumber"]
domingo$cambio4 <- cambio.domingo[4,"VisitNumber"]

domingo <- mutate(domingo, dia_mes = ifelse(VisitNumber < cambio1, 3, 
                                          ifelse(VisitNumber < cambio2, 10, 
                                          ifelse(VisitNumber < cambio3, 17, 
                                          ifelse(VisitNumber < cambio4, 24,31)
                                                      )
                                        ) 
))

##

sabado$cambio1 <- cambio.sabado[1,"VisitNumber"]
sabado$cambio2 <- cambio.sabado[2,"VisitNumber"]
sabado$cambio3 <- cambio.sabado[3,"VisitNumber"]
sabado$cambio4 <- cambio.sabado[4,"VisitNumber"]

sabado <- mutate(sabado, dia_mes = ifelse(VisitNumber < cambio1, 2, 
                                            ifelse(VisitNumber < cambio2, 9, 
                                                   ifelse(VisitNumber < cambio3, 16, 
                                                          ifelse(VisitNumber < cambio4, 23,30)
                                                   )
                                            ) 
))

##

viernes$cambio1 <- cambio.viernes[1,"VisitNumber"]
viernes$cambio2 <- cambio.viernes[2,"VisitNumber"]
viernes$cambio3 <- cambio.viernes[3,"VisitNumber"]
viernes$cambio4 <- cambio.viernes[4,"VisitNumber"]

viernes <- mutate(viernes, dia_mes = ifelse(VisitNumber < cambio1, 1, 
                                          ifelse(VisitNumber < cambio2, 8, 
                                                 ifelse(VisitNumber < cambio3, 15, 
                                                        ifelse(VisitNumber < cambio4, 22,29)
                                                 )
                                          ) 
))

juntar <- rbind(viernes[,c("VisitNumber","dia_mes")],sabado[,c("VisitNumber","dia_mes")],
                domingo[,c("VisitNumber","dia_mes")],lunes[,c("VisitNumber","dia_mes")],
                martes[,c("VisitNumber","dia_mes")],miercoles[,c("VisitNumber","dia_mes")],
                jueves[,c("VisitNumber","dia_mes")])

walmartSpread <- merge(walmartSpread, juntar, by = "VisitNumber")

```

El total de productos comprados tiene la siguiente distribución:

```{r}
p <- ggplot(walmartSpread) +
  geom_histogram(mapping = aes(total_prod),  fill = "#56B4E9", bins = 70) +
  xlab("Total Productos")
ggplotly(p)
```

En la mitad de las visitas realizadas, los clientes compran 4 productos, éste es el valor de su mediana:

```{r}
summary(walmartSpread$total_prod)
```

La indicadora devolución de productos luce como sigue:

```{r}
p <- ggplot(walmartSpread) +
  geom_bar(mapping = aes(as.factor(ind_dev)),  fill = "#56B4E9") +
  xlab("Indicadora Devolución")
ggplotly(p)
```

Aproximadamente, en el 11.6% de las visitas se realiza alguna devolución de producto. Este porcentaje puede considerarse alto.


La distribución de productos devueltos está concentrada en el cero, pues como se vio en la indicadora, en la mayoría de las visitas no se devuelven productos.

```{r}
p <- ggplot(walmartSpread) +
  geom_histogram(mapping = aes(prod_devueltos),  fill = "#56B4E9", bins = 20) +
  xlab("Total Productos Devueltos")
ggplotly(p)
```

De la distribución de la variable *Departamentos visitados* se concluye que en la mayoría de las visitas los clientes compran productos de máximo 5 departamentos diferentes:

```{r}
summary(walmartSpread$departamentos_visitados)
```


```{r}
p <- ggplot(walmartSpread) +
  geom_histogram(mapping = aes(departamentos_visitados),  fill = "#56B4E9", bins = 20) +
  xlab("Total Departamentos")
ggplotly(p)
```

En cuanto al número de productos con diferente UPC, la mayoría de los clientes compran en su visita productos de máximo 8 códigos UPC distintos.

```{r}
summary(walmartSpread$prod_distintos_upc)
```


```{r}
p <- ggplot(walmartSpread) +
  geom_histogram(mapping = aes(prod_distintos_upc),  fill = "#56B4E9", bins = 50) +
  xlab("Productos UPC")
ggplotly(p)
```

Sobre la variable del *día del mes*, se realizó el siguiente análisis para llegar a su construcción: Al juntar las bases train y test, ordenarlas por el código de visita y graficar la distribución de la variable *día de la semana* se observó la siguiente gráfica:

```{r}
walmart.todo <- rbind(walmartSpread[,c(1,3)],walmart.testSpread[,c(1,2)])
walmart.ord <- walmart.todo[order(walmart.todo$VisitNumber),c(1,2)]

walmart.ord <- mutate(walmart.ord, dia = ifelse(Weekday == "Friday", 1, 
                                                ifelse(Weekday == "Saturday", 2,
                                                ifelse(Weekday == "Sunday", 3,
                                                ifelse(Weekday == "Monday", 4,
                                                ifelse(Weekday == "Tuesday", 5,
                                                ifelse(Weekday == "Wednesday", 6, 7
                                                )))))))

ggplot(walmart.ord) +
  geom_point(mapping = aes(VisitNumber,dia)) +
  ylab("Día de la semana") + ylim(c(0,7))

  
```

En esta gráfica, el valor 1 en el eje *y* representa el viernes, el valor 2 el sábado, así sucesivamente hasta el valor 7 que representa al jueves. Al observarla, lleva a pensar que de alguna forma, los códigos de visita están ligados con el tiempo, parece ser que se trata de 31 días iniciando con un jueves y finalizando en domingo. 

Por lo tanto se construyó la variable día del mes, numerando de 1 a 31 los diferentes días de la semana de acuerdo a su código de visita. Su distribución es la siguiente:

```{r}
ggplot(juntar) + 
  geom_point(mapping = aes(VisitNumber,dia_mes))

```


##Preparar base para procesar en Python

Finalmente en R, se guardan los datos como un archivo feather para poder realizar el ajuste de modelos en Python.

```{r, eval=FALSE, echo=TRUE}
path <- "Datos/walmart.feather"
write_feather(walmartSpread, path)
```


##Modelos

Todos los modelos se calcularon en Python, siguiendo esta metodología:

* Se parte la base train en train (train del train) y test (test del train), utilizando muestreo estratificado por la variable objetivo
* Se realiza un grid de hiperparámetros de acuerdo al tipo de modelo (regresión, bosques, etc)
* Se calculan los modelos con el train del train, sobre el grid de hiperparámetros realizando cross validation
* Siguiendo el criterio de optimizar la función log loss, se elige el mejor conjunto de hiperparámetros
* Se calcula el desempeño del modelo con los mejores hiperparámetros sobre el test del train
* Se ajusta un modelo con los mejores hiperparámetros sobre toda la base train
* Se realiza el *predict* sobre el conjunto de prueba
* Se sube esta predicción a kaggle para obtener el desempeño final del modelo

Se ajustaron los siguientes modelos: regresión logística multinomial, bosques aleatorios, máquinas de soporte vectorial, red neuronal. El desempeño final (evaluación de kaggle) de cada uno fue:

| Modelo                       | Parámetros                                | Tiempo Ajuste | Public Score|
| ---------------------------- |:-----------------------------------------:| -------:| -------:|
| Regresión Multinomial        | penalización L1, C = 1                    |   3 hrs |  1.3185 |
| Bosque Aleatorio             | depth = 100, feat = sqrt, split = 10, n_est = 1500                                     |   4 hrs |  2.1320 |
| Máquina de Soporte Vectorial | kernel lineal, C = 10                     |   5 hrs |  1.0820 |
| Red Neuronal                 | alpha 100, 30 capas, 1000 iter, semilla 0 |   4 hrs |  1.0370 |

El mejor ajuste se obtuvo con la red neuronal consiguiendo un log loss muy cercano a 1, es importante mencionar que la máquina de soporte tuvo un desempeño muy similar. Nuestro mejor modelo nos situaría en el lugar 445 del total de 1047 participantes en la competencia, esto es el percentil 42%.

Por último, se ajustó un modelo siguiendo la página http://kaslemr.github.io/Walmart_Kaggle_Competition/, donde el competidor menciona el método final que utilizó para ajustar su modelo.


El competidor utilizó la liberaría **XGB** la cual contiene un algoritmo de *gradient boosting*. Este algoritmo consiste en ensambles de árboles de decisión. La diferencia de esta liberería respecto a otras de ensambles, es el parámetro para forzar a que termine el modelo después de no mejorar en cierto número de iteraciones. De esta manera evita el sobreajuste y su tiempo de entretanmiento suele ser bajo. 

El modelo se ajustó siguiendo su código, parte la base de entrenamiento en train y en test para la construcción del modelo, sin usar validación cruzada ni optimización de hiperparámetros. Tardó 20 minutos en terminar de ajustarse. El desempeño final (kaggle) que se obtuvo fue de **0.9647**, logrando así la métrica de éxito (log loss menor a 1), lo cual nos situaría en la posición 411, percentil 39%.
